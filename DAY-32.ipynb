{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2b566c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Obtaining dependency information for textblob from https://files.pythonhosted.org/packages/1e/d6/40aa5aead775582ea0cf35870e5a3f16fab4b967f1ad2debe675f673f923/textblob-0.19.0-py3-none-any.whl.metadata\n",
      "  Downloading textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nltk>=3.9 (from textblob)\n",
      "  Obtaining dependency information for nltk>=3.9 from https://files.pythonhosted.org/packages/4d/66/7d9e26593edda06e8cb531874633f7c2372279c3b0f46235539fe546df8b/nltk-3.9.1-py3-none-any.whl.metadata\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\users\\navad\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\navad\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\navad\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\navad\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\navad\\anaconda3\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "Downloading textblob-0.19.0-py3-none-any.whl (624 kB)\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/624.3 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/624.3 kB ? eta -:--:--\n",
      "   - ------------------------------------- 30.7/624.3 kB 163.8 kB/s eta 0:00:04\n",
      "   --- ----------------------------------- 61.4/624.3 kB 297.7 kB/s eta 0:00:02\n",
      "   ------- ------------------------------ 122.9/624.3 kB 514.3 kB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 276.5/624.3 kB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 389.1/624.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 450.6/624.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 553.0/624.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  614.4/624.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 624.3/624.3 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.5 MB 3.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.2/1.5 MB 2.8 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.4/1.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.4/1.5 MB 3.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.4/1.5 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.5/1.5 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.5/1.5 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.6/1.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.7/1.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.8/1.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.9/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.1/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.2/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: nltk, textblob\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "Successfully installed nltk-3.9.1 textblob-0.19.0\n"
     ]
    }
   ],
   "source": [
    "! pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79359929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Most Frequent Tokens:\n",
      "package: 7\n",
      "downloading: 4\n",
      "to: 4\n",
      "c: 4\n",
      "is: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\navad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Ensure you have downloaded the necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "\n",
    "def load_text_file(file_path):\n",
    "    \"\"\"Load a text file and return its content.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def tokenize_text(text):\n",
    "    \"\"\"Tokenize the given text using NLTK.\"\"\"\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def calculate_term_frequency(tokens):\n",
    "    \"\"\"Calculate the term frequency (TF) of each token.\"\"\"\n",
    "    return Counter(tokens)\n",
    "\n",
    "def display_top_tokens(term_frequencies, top_n=5):\n",
    "    \"\"\"Display the top N most frequent tokens.\"\"\"\n",
    "    print(f\"Top {top_n} Most Frequent Tokens:\")\n",
    "    for token, freq in term_frequencies.most_common(top_n):\n",
    "        print(f\"{token}: {freq}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the text file\n",
    "    file_path = \"Output for Sentiment Analysis.txt\"  # Replace with your file's path\n",
    "\n",
    "    try:\n",
    "        # Load and process the text\n",
    "        text = load_text_file(file_path)\n",
    "        tokens = tokenize_text(text)\n",
    "\n",
    "        # Filter tokens to include only alphanumeric characters (optional)\n",
    "        tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "\n",
    "        # Calculate term frequency\n",
    "        term_frequencies = calculate_term_frequency(tokens)\n",
    "\n",
    "        # Display the top 5 most frequent tokens\n",
    "        display_top_tokens(term_frequencies, top_n=5)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f6839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
