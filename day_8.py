# -*- coding: utf-8 -*-
"""DAY-8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12RbTuU0TlokOil59-CsVhQJoywpcMsYY

# Write a Python script that:
1. Tokenizes a sample paragraph into words and sentences.
"""

import nltk
nltk.download('all')
sample_paragraph = """Natural Language Processing (NLP) is a fascinating field of Artificial Intelligence.
It focuses on the interaction between computers and human language. Tokenization is the first step in NLP."""
# sentence tokenization
sentences = nltk.sent_tokenize(sample_paragraph)
# word tokenization
words = nltk.word_tokenize(sample_paragraph)
print(f"Original Paragraph:\n{sample_paragraph}")
print(f"\nTokenized Sentences:\n{sentences}")
print(f"\nTokenized Words:\n{words}")